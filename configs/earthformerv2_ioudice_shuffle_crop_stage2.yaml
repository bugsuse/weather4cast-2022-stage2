experiment:  # Settings for the current experiment
  name: 'earthformer'  # name of the current experiment for logging
  experiment_folder: 'stage2'  # folder to save logs 
  sub_folder: 'baseline'  # logging sub-folder
  precision: 16  # bit precision of weights. 32 or 16 
  logging: True  # Toggle logging on/off
dataset: 
  # Available bands: 'IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073'
  sat_bands: ['IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134', 'VIS006', 'VIS008', 'WV_062', 'WV_073']
#   regions: [ 'boxi_0015', 'boxi_0034', 'boxi_0076' ]  # stage-1
  sat_idx: null
  crop_edge: 63 
  regions: [ 'boxi_0015', 'boxi_0034', 'boxi_0076',
             'roxi_0004', 'roxi_0005', 'roxi_0006', 'roxi_0007' ]  # stage-2
  # or, e.g., ['boxi_0015'] if you want to train your model for one region only
  padding: 1
  shuffle: True
  input_product: REFL-BT 
  output_product: RATE 
  out_min: [0.01]
  out_max: [1]
  out_channels: 1 
  in_channels: 11
  swap_time_ch: True #swap the time and channels axis - if set to False (B, T, C, H, W)
  full_opera_context: 1512 # (105+42+105)*6; 
  size_target_center:  252 # 42*6;  
  len_seq_in: 4        # number of input slots per training sequence
  len_seq_predict: 32  # output slots; both still hard-coded in places!
  data_root: '/local/w4c22/'  # stage-1
  years:  [ '2019', '2020' ]  # stage-2
#   years:  [ '2019' ]  # stage-1
#   splits_path: 'data/timestamps_and_splits_2019.csv'  # stage-1
  splits_path: '/local/w4c22/timestamps_and_splits_stage2.csv'  # stage-2
  
  preprocess_OPERA:
    #  # var mean sd min median max length pos.weight.thr_0 
    #  1 RATE 0.07165331 0.6302647 0 0 127.9399 5011989696 6.114572 
    RATE:
      rainfall_rate-500X500: 
        mask: [-9999000.0, inf, nan, max128] #, 0range0.1] # Mostly used for loss function: values added here are added to a mask and not used for loss 
#         map: [[lessthan0.0, 0], [greaterthan0.0, 1], [-8888000.0, 0], [-9999000.0, 0], [inf, 0], [nan, 0]]   #Mostly used for input preprocessing   # 1. map values   # stage-1
        map: [[lessthan0.2, 0], [greaterthan0.2, 1], [0.2,1], [-8888000.0, 0], [-9999000.0, 0], [inf, 0], [nan, 0]]   #Mostly used for input preprocessing   # 1. map values   # stage-2
#        mean_std: [0.07165331, 0.6302647]
        range: [0, 128]          # 2. we evaluate only pixels in this range
        standardise: False       # 3. use log(x+1) instead & normalize (x/max)
        bin: False     
        min_max: null 
  preprocess_HRIT:  # 1: map values, 2: normalise in range per variable if process==True
    #  # var mean sd min median max length
    #  1 IR_016 0.06605569 0.09920627 0 0.006609255 1.018736 4371869376 
    #  2 IR_039 273.2187 15.98847 -2.968737 276.0403 336.2159 4371869376
    #  3 IR_087 268.3977 17.49075 -0.1731693 271.9306 326.3914 4371869376 
    #  4 IR_097 246.1366 10.81174 -0.05971194 246.4856 301.0066 4371869376 
    #  5 IR_108 270.1535 18.49373 -0.6266653 274.0552 338.0375 4371869376 
    #  6 IR_120 268.7993 18.42736 -0.4006808 272.9807 337.3713 4371869376 
    #  7 IR_134 250.6491 11.70623 -0.5645727 252.9884 300.8559 4371869376 
    #  8 VIS006 0.06711527 0.1101766 0 0.01692321 1.002381 4371869376 
    #  9 VIS008 0.08736397 0.1326554 0 0.01656201 1.100475 4371869376 
    # 10 WV_062 232.1964 5.531017 -2.086555 232.3866 260.9901 4371869376 
    # 11 WV_073 248.0414 9.495061 -0.4933934 250.0049 289.8742 4371869376 
    IR_016: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 1.02]
      mean_std: [0.06605569, 0.09920627]
      standardise: True 
    IR_039: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 350]
      mean_std: [273.2187, 15.98847]
      standardise: True 
    IR_087: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 350]
      mean_std: [268.3977, 17.49075]
      standardise: True 
    IR_097: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 350]
      mean_std: [246.1366, 10.81174]
      standardise: True 
    IR_108: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 350]
      mean_std: [270.1535, 18.49373]
      standardise: True 
    IR_120: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 350]
      mean_std: [268.7993, 18.42736]
      standardise: True 
    IR_134: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 350]
      mean_std: [250.6491, 11.70623]
      standardise: True 
    VIS006: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 1.02]
      mean_std: [0.06711527, 0.1101766]
      standardise: True 
    VIS008: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 1.2]  
      mean_std: [0.08736397, 0.1326554]
      standardise: True 
    WV_062: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 300]
      mean_std: [232.1964, 5.531017]
      standardise: True 
    WV_073: 
      map: [[inf, 0], [nan, 0]]
      range: [0, 300]
      mean_std: [248.0414, 9.495061]
      standardise: True
    
train:    # model training settings
  batch_size: 12 # 40
  max_epochs: 90
  n_workers: 12  # 16
  loss: ioudiceloss 
  pos_weight: 6.114572
  early_stopping: True
  patience: 10
  lr: 1e-4
  weight_decay: 2e-2 
  gradient_clip_val: 2.0
  gradient_clip_algorithm: value
  scale_factor: 2 

  optim: 'adam'
  sgd:
    momentum : 0.9
  adam:
    weight_decay : 0.000005

  scheduler : 'reducelr'
  reducelr:
    mode : 'min'
    factor : 0.5
    patience : 2
    verbose : True
  reducelr_monitor : 'val_loss'

  lossfx:
    alpha : 0.5
    beta: 0.5
    gamma : 0.25
    reduction : 'mean'
    num_classes : 2

  sigmoid: true
  thresholds:
    combine: True 
    combine_threshold: 0
    boxi_0015: 0.001
    boxi_0034: 0.1
    boxi_0076: 0.1
    roxi_0004: 0.001
    roxi_0005: 0.001
    roxi_0006: 0.001
    roxi_0007: 0.1
    roxi_0008: 0.001
    roxi_0009: 0.825
    roxi_0010: 0.825

model:    # model definition settings
  input_shape: [4, 128, 128, 11]
  target_shape: [32, 128, 128, 1]
  base_units: 128
  block_units: null
  scale_alpha: 1.0

  enc_depth: [1, 1]
  dec_depth: [1, 1]
  enc_use_inter_ffn: true
  dec_use_inter_ffn: true
  dec_hierarchical_pos_embed: true

  downsample: 2
  downsample_type: "patch_merge"
  upsample_type: "upsample"

  num_global_vectors: 8
  use_dec_self_global: true
  dec_self_update_global: true
  use_dec_cross_global: true
  use_global_vector_ffn: true
  use_global_self_attn: false
  separate_global_qkv: false
  global_dim_ratio: 1

  self_pattern: "axial"
  cross_self_pattern: "axial"
  cross_pattern: "cross_1x1"
  cross_last_n_frames: null

  attn_drop: 0.1
  proj_drop: 0.1
  ffn_drop: 0.1
  num_heads: 4

  ffn_activation: "gelu"
  gated_ffn: false
  norm_layer: "layer_norm"
  padding_type: "zeros"
  pos_embed_type: "t+h+w"
  use_relative_pos: true
  self_attn_use_final_proj: true
  dec_use_first_self_attn: false

  z_init_method: "zeros"
  checkpoint_level: 0

  initial_downsample_type: "stack_conv"
  initial_downsample_activation: "leaky"
  initial_downsample_stack_conv_num_layers: 3
  initial_downsample_stack_conv_dim_list: [64, 128, 128]
  initial_downsample_stack_conv_downscale_list: [3, 2, 2]
  initial_downsample_stack_conv_num_conv_list: [2, 2, 2]

  attn_linear_init_mode: "0"
  ffn_linear_init_mode: "0"
  conv_init_mode: "0"
  down_up_linear_init_mode: "0"
  norm_init_mode: "0"

predict:  # model prediction settings
  submission_out_dir: 'submission' 
  region_to_predict: boxi_0015  # must match one of the names defined in 'dataset' / 'regions'
  year_to_predict: 2019
